---
hide_table_of_contents: true
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# ğŸ¤– Intelligence artificielle, TP2

<Tabs queryString="onglet">

    <TabItem value="ia" label="ğŸ¤– Intelligence artificielle" default>

        :::info ğŸ¤– Qu'est-ce que l'IA?
        L'intelligence artificielle (IA) est un domaine de l'informatique visant Ã  crÃ©er des systÃ¨mes capables d'effectuer des tÃ¢ches qui nÃ©cessitent normalement l'intelligence humaine, telles que la reconnaissance vocale, la vision par ordinateur, la prise de dÃ©cision et le traitement du langage naturel.

        Dans les derniÃ¨res annÃ©es, l'utilisation d'outils basÃ©s sur l'IA, comme les modÃ¨les de langage (ex: ChatGPT), s'est largement dÃ©mocratisÃ©e, rendant ces technologies accessibles Ã  un public plus large. Cela a stimulÃ© un intÃ©rÃªt accru pour l'IA et intensifiÃ© son dÃ©veloppement. Cependant, cette popularisation a Ã©galement permis de mieux comprendre les capacitÃ©s et les limites de l'IA, tout en soulevant des questions Ã©thiques et sociÃ©tales importantes.
        :::

        :::tip ğŸ“œ Bref historique
        Ã‡a a Ã©tÃ© inventÃ© hier, l'intelligence artificielle?<br />
        Non, pas vraiment!<br />
        L'IA a une histoire riche qui remonte aux annÃ©es 1950, avec des avancÃ©es majeures dans les dÃ©cennies suivantes. Voici un aperÃ§u des principales Ã©tapes de son Ã©volution :

        | PÃ©riode | Jalons | IdÃ©e dominante |
        |---------|--------|----------------|
        | 1950â€“1960 | Test de Turing, Dartmouth 1956 | Symbolisme, logique |
        | 1970â€“1980 | SystÃ¨mes experts | RÃ¨gles si-alors |
        | 1990â€“2005 | Renaissance de l'apprentissage statistique | DonnÃ©es + optimisation |
        | 2012â€“2020 | Explosion du deep learning (ImageNet) | RÃ©seaux profonds |
        | 2020+ | ModÃ¨les fondamentaux (LLM), efficience | ScalabilitÃ©, coÃ»t Ã©nergÃ©tique |

        - Pour la petite histoire, durant la Seconde Guerre mondiale, Alan Turing a dÃ©veloppÃ© des concepts fondamentaux en informatique et en cryptographie, afin de dÃ©chiffrer les codes ennemis des machines Enigma des Allemands. AprÃ¨s la guerre, il a proposÃ© en 1950 un test pour Ã©valuer l'intelligence d'une machine, et le terme *intelligence artificielle* a Ã©tÃ© officiellement introduit lors de la confÃ©rence de Dartmouth en 1956. Depuis, l'IA a connu des pÃ©riodes d'enthousiasme et de scepticisme, mais elle est devenue un domaine central de la recherche informatique et de l'industrie technologique.

        - Les annÃ©es 2010 ont vu exploser le deep learning grÃ¢ce Ã  la disponibilitÃ© de grandes quantitÃ©s de donnÃ©es et Ã  la puissance de calcul accrue, menant Ã  des avancÃ©es spectaculaires en vision par ordinateur et en traitement du langage naturel. Aujourd'hui, l'IA continue d'Ã©voluer rapidement, avec des applications dans presque tous les secteurs industriels.

        - En 2024, l'IA gÃ©nÃ©rative, notamment les modÃ¨les de langage comme GPT-4, a rÃ©volutionnÃ© la maniÃ¨re dont les machines interagissent avec les humains, ouvrant de nouvelles perspectives et dÃ©fis pour l'avenir.
        :::

        :::info Domaines d'application
        L'IA est utilisÃ©e dans de nombreux domaines pour automatiser des tÃ¢ches, amÃ©liorer l'efficacitÃ© et offrir de nouvelles capacitÃ©s. Voici quelques exemples notables :
        | Domaine | Exemples |
        |---------|----------|
        | Vision | Reconnaissance d'objets, segmentation |
        | Langage | Traduction, agents conversationnels |
        | SantÃ© | Aide diagnostique, imagerie |
        | Sciences | Analyse donnÃ©es expÃ©rimentales |
        | Ã‰nergie | Optimisation consommation |
        :::

        :::warning Enjeux Ã©thiques
        L'IA soulÃ¨ve plusieurs enjeux Ã©thiques importants, notamment :
        - **Biais et discrimination** : Les modÃ¨les d'IA peuvent reproduire ou amplifier des biais prÃ©sents dans les donnÃ©es d'entraÃ®nement, conduisant Ã  des dÃ©cisions injustes (ex: racisme, sexisme, etc.).
        - **Vie privÃ©e** : L'utilisation de donnÃ©es personnelles pour entraÃ®ner des modÃ¨les d'IA peut compromettre la confidentialitÃ© des individus.
        - **Transparence** : Les systÃ¨mes d'IA, en particulier les modÃ¨les complexes comme les rÃ©seaux de neurones profonds, peuvent Ãªtre difficiles Ã  interprÃ©ter, rendant leurs dÃ©cisions opaques.
        - **ResponsabilitÃ©** : DÃ©terminer qui est responsable des actions d'une IA, surtout en cas d'erreur ou de prÃ©judice, est un dÃ©fi juridique et Ã©thique.
        - **Impact sur l'emploi** : L'automatisation par l'IA peut entraÃ®ner des pertes d'emplois dans certains secteurs, nÃ©cessitant une rÃ©flexion sur la reconversion professionnelle et la formation.
        :::

    </TabItem>

    <TabItem value="ml" label="ğŸ§ ğŸ§® Apprentissage machine">

        :::tip ğŸ§ ğŸ§® Qu'est-ce que l'apprentissage machine?
        L'apprentissage machine (*Machine Learning*, ML) est une branche de l'intelligence artificielle qui se concentre sur le dÃ©veloppement d'algorithmes et de modÃ¨les permettant aux ordinateurs d'apprendre Ã  partir de donnÃ©es, sans Ãªtre explicitement programmÃ©s pour chaque tÃ¢che spÃ©cifique. En utilisant des techniques statistiques, les modÃ¨les de ML identifient des patterns dans les donnÃ©es et font des prÃ©dictions ou prennent des dÃ©cisions basÃ©es sur ces patterns.
        :::

        :::info Pipeline typique d'apprentissage machine
        Voici un diagramme qui prÃ©sente les Ã©tapes clÃ©s d'un projet typique d'apprentissage machine, depuis la collecte des donnÃ©es brutes jusqu'Ã  la gÃ©nÃ©ration de prÃ©dictions Ã  l'aide d'un modÃ¨le entraÃ®nÃ© :

        <Row>
            <Column size={4}>
                ```mermaid
                flowchart TD
                A["ğŸ“¥ DonnÃ©es brutes"]
                B["ğŸ§¹ PrÃ©traitement"]
                C["ğŸ§© Extraction de caractÃ©ristiques"]
                D["ğŸ§  Choix du modÃ¨le"]
                E["ğŸ¯ EntraÃ®nement"]
                F["âœ… ModÃ¨le entraÃ®nÃ©"]
                G["ğŸ“Š Ã‰valuation"]
                H["ğŸš€ PrÃ©dictions"]
                A --> B --> C --> D --> E --> F --> G --> H
                ```
            </Column>
            <Column size={8}>
                ### ğŸ“¥ DonnÃ©es brutes
                - DonnÃ©es collectÃ©es Ã  partir de diffÃ©rentes sources : fichiers CSV, images, texte, etc.
                - Elles sont souvent incomplÃ¨tes, hÃ©tÃ©rogÃ¨nes ou bruitÃ©es.

                ### ğŸ§¹ PrÃ©traitement
                - Nettoyage : valeurs manquantes, doublons, normalisation, encodage.
                - AmÃ©liore la qualitÃ© des donnÃ©es et rÃ©duit lâ€™erreur.

                ### ğŸ§© Extraction de caractÃ©ristiques
                - Transformation des donnÃ©es en caractÃ©ristiques (*features*).
                - SÃ©lection dâ€™attributs pertinents ou crÃ©ation de nouvelles variables.

                ### ğŸ§  Choix du modÃ¨le
                - Choix de lâ€™algorithme : rÃ©gression, arbres de dÃ©cision, forÃªts, rÃ©seaux de neurones, etc.
                - Chaque modÃ¨le a ses forces et ses limites.

                ### ğŸ¯ EntraÃ®nement
                - Ajustement des paramÃ¨tres du modÃ¨le pour minimiser lâ€™erreur.
                - Inclut souvent des itÃ©rations (epochs) et une validation.
                - Peut Ãªtre exigeant en ressources (temps, mÃ©moire, Ã©nergie).

                ### âœ… ModÃ¨le entraÃ®nÃ©
                - ParamÃ¨tres optimisÃ©s et structure fixe.
                - PrÃªt Ã  Ãªtre Ã©valuÃ© sur des donnÃ©es nouvelles.

                ### ğŸ“Š Ã‰valuation
                - Mesure de la performance sur un ensemble de test indÃ©pendant.
                - Permet de valider la qualitÃ© rÃ©elle du modÃ¨le entraÃ®nÃ©.

                ### ğŸš€ PrÃ©dictions
                - Utilisation du modÃ¨le en contexte rÃ©el pour gÃ©nÃ©rer des prÃ©dictions.
                - IntÃ©gration dans une application, un service ou un systÃ¨me automatisÃ©.
            </Column>
        </Row>
        :::

        :::tip ğŸ¯ EntraÃ®nement

        L'entraÃ®nement est le processus par lequel un modÃ¨le d'apprentissage machine apprend Ã  partir des donnÃ©es.
        Il consiste Ã  ajuster les paramÃ¨tres internes du modÃ¨le afin de minimiser une **fonction de perte** ğŸ“‰
        qui mesure l'Ã©cart entre les prÃ©dictions du modÃ¨le ğŸ¤– et les valeurs rÃ©elles ğŸ·ï¸.

        Pour obtenir un modÃ¨le **robuste et performant**, l'entraÃ®nement nÃ©cessite souvent des ressources importantes :

        - **ğŸ“Š DonnÃ©es** : Plus il y a de donnÃ©es de qualitÃ©, meilleur sera l'apprentissage.
        - **â±ï¸ Temps de calcul** : L'entraÃ®nement peut Ãªtre long, surtout pour les modÃ¨les complexes.
        - **ğŸ’» Puissance de calcul** : Utilisation de GPU/TPU âš¡ pour accÃ©lÃ©rer les calculs.
        - **ğŸ§  MÃ©moire** : Stockage des donnÃ©es et des paramÃ¨tres du modÃ¨le pendant l'entraÃ®nement.
        - **ğŸ”‹ Ã‰nergie** : Consommation Ã©nergÃ©tique importante liÃ©e au matÃ©riel informatique intensif.
        :::

        :::warning ğŸ”¥ Surapprentissage (overfitting) et jeux de donnÃ©es

        Le **surapprentissage** se produit lorsqu'un modÃ¨le apprend *trop bien* les dÃ©tails et le **bruit** des donnÃ©es d'entraÃ®nement,
        au point de perdre sa capacitÃ© Ã  **gÃ©nÃ©raliser** Ã  de nouvelles donnÃ©es.

        Ce concept peut sembler contre-intuitif ğŸ¤” : comment un modÃ¨le peut-il Ãªtre *trop bon* ?

        Imaginez un Ã©tudiant qui **mÃ©morise par cÅ“ur** chaque question dâ€™un examen passÃ© ğŸ“šğŸ§ ,
        sans comprendre rÃ©ellement les concepts. Lorsquâ€™il est confrontÃ© Ã  un nouvel examen avec des questions diffÃ©rentes â“â¡ï¸â“, il Ã©choue.

        Le surapprentissage est similaire :
        le modÃ¨le performe **exceptionnellement bien** sur lâ€™entraÃ®nement ğŸ’¯,
        mais Ã©choue sur des donnÃ©es jamais vues auparavant ğŸš«.

        Pour Ã©viter ce problÃ¨me, plusieurs stratÃ©gies existent :
        - **ğŸ›¡ï¸ RÃ©gularisation**
        - **â³ ArrÃªt prÃ©coce (*early stopping*)**
        - **ğŸ“‚ SÃ©paration des donnÃ©es** en ensembles d'entraÃ®nement, validation et test

        :::

        :::tip ğŸ¯ SÃ©paration des donnÃ©es

        Pour prÃ©venir le surapprentissage (*overfitting*), un jeu de donnÃ©es est gÃ©nÃ©ralement divisÃ© en **trois ensembles distincts**, chacun ayant un rÃ´le bien prÃ©cis.<br />
        On pourrait par exemple utiliser la rÃ©partition classique **70% - 15% - 15%** :

        ```mermaid
        flowchart TD
        A["ğŸ“‚ Jeu de donnÃ©es complet"] --> B["ğŸ“˜ 70% EntraÃ®nement"]
        A --> C["ğŸ“™ 15% Validation"]
        A --> D["ğŸ“— 15% Test"]
        ```

        ### Les trois ensembles
        - **ğŸ“˜ EntraÃ®nement (*training set*)**
          Sert Ã  **apprendre** : le modÃ¨le ajuste ses paramÃ¨tres internes.
        - **ğŸ“™ Validation (*validation set*)**
          UtilisÃ© pour **ajuster les hyperparamÃ¨tres** et surveiller le surapprentissage durant lâ€™entraÃ®nement.
        - **ğŸ“— Test (*test set*)**
          UtilisÃ© **uniquement Ã  la fin** pour mesurer la performance rÃ©elle du modÃ¨le sur des donnÃ©es jamais vues.

        ### Exemple pratique

        Pour un jeu de **1000 Ã©chantillons** ğŸ§ª :

        - **70%** â†’ 700 pour lâ€™entraÃ®nement
        - **15%** â†’ 150 pour la validation
        - **15%** â†’ 150 pour le test

        La sÃ©paration doit Ãªtre faite **alÃ©atoirement** ğŸ² pour garantir que chaque ensemble reste reprÃ©sentatif.
        :::

        :::info Exemples d'algorithmes courants
        Voici quelques algorithmes d'apprentissage machine couramment utilisÃ©s, classÃ©s par type :
        | Type | Algorithmes | Description |
        |------|-------------|-------------|
        | RÃ©gression | RÃ©gression linÃ©aire, rÃ©gression logistique | PrÃ©dire une valeur continue ou une probabilitÃ© |
        | Arbres de dÃ©cision | CART, Random Forest, Gradient Boosting | ModÃ¨les basÃ©s sur des rÃ¨gles hiÃ©rarchiques |
        | Machines Ã  vecteurs de support | SVM | Trouver l'hyperplan optimal pour la classification |
        | RÃ©seaux de neurones | Perceptron, CNN, RNN | ModÃ¨les en couches pour donnÃ©es complexes |
        | Clustering | K-means, DBSCAN | Regrouper des donnÃ©es non Ã©tiquetÃ©es en clusters |
        :::

        :::note Exemple d'implÃ©mentation avec scikit-learn
        Voici un exemple simple d'utilisation de la bibliothÃ¨que `scikit-learn` en Python pour effectuer une **classification supervisÃ©e** sur un vrai jeu de donnÃ©es classique : le jeu de donnÃ©es **Iris** (`sklearn.datasets.load_iris`).

        Ce script suit les grandes Ã©tapes du pipeline vu plus haut :
        chargement des donnÃ©es â†’ sÃ©paration entraÃ®nement/validation/test â†’ entraÃ®nement â†’ Ã©valuation â†’ prÃ©dictions.

        Vous pouvez le rouler tel quel dans un environnement Python avec `scikit-learn` installÃ©.

        ```python
        # 1. Import des bibliothÃ¨ques nÃ©cessaires
        from sklearn.datasets import load_iris
        from sklearn.model_selection import train_test_split
        from sklearn.pipeline import make_pipeline
        from sklearn.preprocessing import StandardScaler
        from sklearn.linear_model import LogisticRegression
        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

        # 2. Charger le jeu de donnÃ©es Iris
        iris = load_iris()
        X = iris.data           # CaractÃ©ristiques (features) : mesures des fleurs
        y = iris.target         # Ã‰tiquettes (labels) : espÃ¨ce d'Iris (0, 1 ou 2)

        print("Noms des features :", iris.feature_names)
        print("Noms des classes  :", iris.target_names)
        print("Taille du jeu de donnÃ©es :", X.shape, "Ã©chantillons\n")

        # 3. SÃ©parer les donnÃ©es en train / validation / test
        #    Ici, on commence par sÃ©parer en (train+val) et test,
        #    puis on re-sÃ©pare train+val en train et val.

        # 15% des donnÃ©es pour le test final
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=0.15, random_state=42, stratify=y
        )

        # Sur le 85% restant, on garde 70% pour l'entraÃ®nement et 15% pour la validation
        # 15% de 100% = 0.15 â†’ 15% de 85% â‰ˆ 17.6% â†’ on ajuste la proportion
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp
        )

        print("Taille ensemble d'entraÃ®nement :", X_train.shape[0])
        print("Taille ensemble de validation   :", X_val.shape[0])
        print("Taille ensemble de test         :", X_test.shape[0], "\n")

        # 4. DÃ©finir un modÃ¨le + pipeline de prÃ©traitement
        #    Ici : Standardisation des features + RÃ©gression logistique
        model = make_pipeline(
            StandardScaler(),
            LogisticRegression(max_iter=1000, random_state=42)
        )

        # 5. EntraÃ®ner le modÃ¨le sur l'ensemble d'entraÃ®nement
        model.fit(X_train, y_train)

        # 6. Ã‰valuer sur l'ensemble de validation
        y_val_pred = model.predict(X_val)
        val_accuracy = accuracy_score(y_val, y_val_pred)
        print("Accuracy sur l'ensemble de validation :", round(val_accuracy, 3))

        # 7. Ã‰valuer sur l'ensemble de test (performance finale)
        y_test_pred = model.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_test_pred)
        print("Accuracy sur l'ensemble de test       :", round(test_accuracy, 3), "\n")

        print("Matrice de confusion (test) :")
        print(confusion_matrix(y_test, y_test_pred), "\n")

        print("Rapport de classification (test) :")
        print(classification_report(y_test, y_test_pred, target_names=iris.target_names))
        :::

    </TabItem>

    <TabItem value="dl" label="ğŸ§ ğŸ•¸ï¸ Apprentissage profond">

        :::info ğŸ§ ğŸ•¸ï¸ Qu'est-ce que l'apprentissage profond?
        L'apprentissage profond (*Deep Learning*, DL) est une sous-catÃ©gorie de l'apprentissage machine qui utilise des rÃ©seaux de neurones artificiels profonds pour modÃ©liser et rÃ©soudre des problÃ¨mes complexes. Ces rÃ©seaux sont composÃ©s de plusieurs couches de neurones interconnectÃ©s, permettant au modÃ¨le d'apprendre des reprÃ©sentations hiÃ©rarchiques des donnÃ©es.

        Le DL est particuliÃ¨rement efficace pour traiter des donnÃ©es non structurÃ©es telles que les images, le texte et l'audio, et a conduit Ã  des avancÃ©es significatives dans des domaines comme la vision par ordinateur, le traitement du langage naturel et la reconnaissance vocale.
        :::

        :::tip Applications avancÃ©es
        L'apprentissage profond a permis des avancÃ©es significatives dans divers domaines, notamment :
        | Domaine | Exemples |
        |---------|----------|
        | Vision par ordinateur | Reconnaissance faciale, dÃ©tection d'objets |
        | Traitement du langage naturel | Traduction automatique, chatbots |
        | GÃ©nÃ©ration de contenu | CrÃ©ation d'images, musique, texte |
        | SantÃ© | Diagnostic mÃ©dical, analyse d'images mÃ©dicales |
        :::

        :::info ModÃ¨le de base : le neurone artificiel ğŸ¤–

        Le neurone artificiel est l'unitÃ© de base des rÃ©seaux de neurones en apprentissage profond.
        Il reÃ§oit plusieurs entrÃ©es, applique des poids Ã  chacune d'elles, additionne le tout avec un biais, puis applique une **fonction d'activation** pour produire une sortie.

        Ã€ la base, il est inspirÃ© du fonctionnement d'un neurone biologique :

        ```mermaid
        flowchart LR

        subgraph Bio["ğŸ§¬ Neurone biologique"]
            A1["Dendrites<br/><sub>ReÃ§oivent des signaux chimiques/Ã©lectriques</sub>"]
            A2["Soma (corps cellulaire)<br/><sub>IntÃ¨gre les signaux</sub>"]
            A3["Axone<br/><sub>Transmet un signal Ã©lectrique</sub>"]
            A4["Synapses<br/><sub>Transmission chimique vers d'autres neurones</sub>"]

            A1 --> A2 --> A3 --> A4
        end

        subgraph Art["ğŸ¤– Neurone artificiel"]
            B1["EntrÃ©es xâ‚, xâ‚‚, â€¦"]
            B2["Poids wâ‚, wâ‚‚, â€¦"]
            B3["Somme pondÃ©rÃ©e<br/>Î£(wáµ¢Â·xáµ¢ + biais)"]
            B4["Fonction d'activation<br/>f(Î£)"]
            B5["Sortie y"]

            B1 --> B3
            B2 --> B3
            B3 --> B4 --> B5
        end

        Bio ---> Art
        ```

        :::

        :::warning Neurone artificiel vs neurone biologique
        - Bien que le **neurone artificiel** sâ€™inspire du fonctionnement du **neurone biologique**, il ne sâ€™agit que dâ€™une **approximation mathÃ©matique trÃ¨s simplifiÃ©e**.
        - Les neurones biologiques sont des structures extraordinairement complexes :
        ils communiquent au moyen de **signaux Ã©lectriques et chimiques**, sâ€™adaptent en permanence, possÃ¨dent des milliers de connexions (synapses) et fonctionnent selon des principes **continu** (analogique) plutÃ´t que numÃ©rique.
        - Certains projets ambitieux, comme le **Blue Brain Project**, tentent de modÃ©liser le cerveau humain.
        Mais en pratique, les neurones artificiels utilisÃ©s en apprentissage machine restent des abstractions conÃ§ues pour rÃ©soudre des tÃ¢ches spÃ©cifiques, sans chercher Ã  reproduire la complexitÃ© rÃ©elle du cerveau.
        - En rÃ©alitÃ©, nous comprenons encore mal le fonctionnement dÃ©taillÃ© dâ€™un seul neurone biologique.
        Alors imaginer modÃ©liser le cerveau humain dans son ensemble â€” qui compte environ **100 milliards de neurones**, interconnectÃ©s par **100 trillions de synapses** â€” dÃ©passe largement nos capacitÃ©s actuelles de simulation et de comprÃ©hension.
        - MÃªme avec les avancÃ©es spectaculaires en intelligence artificielle, la complexitÃ© du cerveau humain demeure **infiniment supÃ©rieure** Ã  ce que nos modÃ¨les peuvent reproduire.
        - Pour aller plus loin, vous pouvez lire *[Le cerveau, lâ€™univers dans votre tÃªte](https://www.davidfortin.ca/styled-2/)* du neurochirurgien David Fortin â€” un excellent ouvrage de vulgarisation.
        :::

        :::note Perceptron
        Le quessÃ©?? Le **perceptron** est l'un des modÃ¨les de neurones artificiels les plus simples et les plus fondamentaux en apprentissage machine. Il a Ã©tÃ© introduit par Frank Rosenblatt en 1958. Le perceptron est conÃ§u pour effectuer des tÃ¢ches de classification binaire, c'est-Ã -dire qu'il peut distinguer entre deux classes diffÃ©rentes.

        Le perceptron fonctionne en prenant plusieurs entrÃ©es pondÃ©rÃ©es, en les sommant, puis en appliquant une fonction d'activation (gÃ©nÃ©ralement une fonction seuil) pour produire une sortie binaire (0 ou 1).
        ```mermaid
        flowchart LR
            A1["EntrÃ©es xâ‚, xâ‚‚, â€¦"]
            A2["Poids wâ‚, wâ‚‚, â€¦"]
            A3["Somme pondÃ©rÃ©e<br/>Î£(wáµ¢Â·xáµ¢ + biais)"]
            A4["Fonction d'activation<br/>f(Î£)"]
            A5["Sortie y"]
            A1 --> A3
            A2 --> A3
            A3 --> A4 --> A5
        ```

        Le code suivant illustre le fonctionnement d'un perceptron simple en Python pour apprendre la fonction logique ET :
        ```python
        # DonnÃ©es d'entraÃ®nement (ET logique)
        X = [(0,0), (0,1), (1,0), (1,1)]
        y = [0, 0, 0, 1]

        # Poids initiaux
        w = [0.1, -0.2]
        b = 0.0
        lr = 0.1

        # Fonction d'activation (seuil)
        def activation(z):
            return 1 if z >= 0.5 else 0

        # EntraÃ®nement
        for epoch in range(20):
            for (x1, x2), cible in zip(X, y):
                z = w[0]*x1 + w[1]*x2 + b
                pred = activation(z)
                err = cible - pred

                # Mise Ã  jour des poids
                w[0] += lr * err * x1
                w[1] += lr * err * x2
                b    += lr * err

        # Test final
        for (x1, x2) in X:
            z = w[0]*x1 + w[1]*x2 + b
            print((x1, x2), activation(z))
        ```

        Le perceptron peut Ãªtre entraÃ®nÃ© Ã  l'aide d'un algorithme simple qui ajuste les poids en fonction des erreurs de classification sur un ensemble de donnÃ©es d'entraÃ®nement. Cependant, le perceptron a des limitations, notamment son incapacitÃ© Ã  rÃ©soudre des problÃ¨mes non linÃ©aires, ce qui a conduit au dÃ©veloppement de rÃ©seaux de neurones plus complexes et profonds.
        :::

        :::info ğŸ”— RÃ©seaux de neurones

        Un **rÃ©seau de neurones artificiels** est une architecture composÃ©e de plusieurs couches de neurones interconnectÃ©s :

        - une **couche dâ€™entrÃ©e** qui reÃ§oit les donnÃ©es (features),
        - une ou plusieurs **couches cachÃ©es** qui transforment progressivement les reprÃ©sentations,
        - une **couche de sortie** qui produit la prÃ©diction (classe, probabilitÃ©, valeur numÃ©rique, etc.).

        Chaque neurone applique une combinaison linÃ©aire de ses entrÃ©es (poids + biais), puis une **fonction dâ€™activation non linÃ©aire**.
        En empilant plusieurs couches, le rÃ©seau peut apprendre des **reprÃ©sentations hiÃ©rarchiques** de plus en plus abstraites.

        Le schÃ©ma ci-dessous illustre un rÃ©seau simple avec :

        - 3 neurones dâ€™entrÃ©e
        - 2 couches cachÃ©es
        - 1 neurone de sortie

        ```mermaid
        flowchart LR

            %% Couches
            subgraph Input["Couche d'entrÃ©e"]
                X1["x1"]
                X2["x2"]
                X3["x3"]
            end

            subgraph Hidden1["Couche cachÃ©e 1"]
                H11["h1_1"]
                H12["h1_2"]
                H13["h1_3"]
            end

            subgraph Hidden2["Couche cachÃ©e 2"]
                H21["h2_1"]
                H22["h2_2"]
            end

            subgraph Output["Couche de sortie"]
                Y["y"]
            end

            %% Connexions entrÃ©e -> couche cachÃ©e 1 (fully connected)
            X1 --> H11
            X1 --> H12
            X1 --> H13

            X2 --> H11
            X2 --> H12
            X2 --> H13

            X3 --> H11
            X3 --> H12
            X3 --> H13

            %% Connexions couche cachÃ©e 1 -> couche cachÃ©e 2
            H11 --> H21
            H11 --> H22

            H12 --> H21
            H12 --> H22

            H13 --> H21
            H13 --> H22

            %% Connexions couche cachÃ©e 2 -> sortie
            H21 --> Y
            H22 --> Y
        ```

        Dans un vrai modÃ¨le de deep learning, il peut y avoir :

        - beaucoup plus de neurones par couche,
        - de nombreuses couches cachÃ©es (rÃ©seaux â€œprofondsâ€),
        - des types de couches spÃ©cialisÃ©s (convolutions, rÃ©currences, attention, etc.),
        mais lâ€™idÃ©e de base reste la mÃªme : **propager lâ€™information de gauche Ã  droite** en la transformant Ã  chaque couche.

        :::


        :::tip ğŸ¾ Exemple : classifier des animaux dans des photos

        Dans un rÃ©seau profond entraÃ®nÃ© Ã  **reconnaÃ®tre des animaux dans des images**, les couches nâ€™apprennent pas toutes la mÃªme chose :

        - Les **premiÃ¨res couches** repÃ¨rent surtout des **motifs trÃ¨s simples** : bords, orientations, contrastes.
        - Les **couches intermÃ©diaires** apprennent des **textures et motifs locaux** : pelage, motifs de fourrure, contours dâ€™oreilles, etc.
        - Les **couches plus profondes** combinent ces Ã©lÃ©ments pour reconnaÃ®tre des **parties dâ€™objets** : yeux, museau, pattesâ€¦
        - Les **derniÃ¨res couches** construisent une reprÃ©sentation globale de lâ€™**animal entier** et produisent la **classe prÃ©dite** (chat, chien, oiseau, etc.).

        Ce schÃ©ma illustre cette montÃ©e progressive en abstraction :

        ```mermaid
        flowchart LR

            I["ğŸ“· Image d'entrÃ©e<br/><sub>chat, chien, oiseauâ€¦</sub>"] --> L1
            subgraph C1["Couche 1"]
                L1["Bords & orientations<br/><sub>lignes, contours simples</sub>"]
            end

            C1 --> L2
            subgraph C2["Couche 2"]
                L2["Textures & motifs locaux<br/><sub>pelage, tÃ¢ches, motifs</sub>"]
            end

            C2 --> L3
            subgraph C3["Couche 3"]
                L3["Parties d'objets<br/><sub>yeux, oreilles, pattes</sub>"]
            end

            C3 --> L4
            subgraph C4["Couche 4+"]
                L4["ReprÃ©sentations d'animaux<br/><sub>forme globale : 'chat', 'chien', 'oiseau'</sub>"]
            end

            L4 --> Y["ğŸ¯ Sortie<br/><sub>classe prÃ©dite</sub>"]
        ```

        Dans un tel modÃ¨le de rÃ©seau de neurones convolutifs (*Convolutional Neural Network, CNN*), ces â€œcouchesâ€ sont des **couches convolutionnelles** apprenant automatiquement ces niveaux de reprÃ©sentation, sans que lâ€™on dise explicitement au modÃ¨le â€œvoici un bordâ€ ou â€œvoici une patteâ€ : il les dÃ©couvre Ã  partir des donnÃ©es et se construit sa propre hiÃ©rarchie de caractÃ©ristiques.

        :::

        :::info Architectures courantes
        Voici quelques architectures de rÃ©seaux de neurones couramment utilisÃ©es en apprentissage profond :
        | Architecture | Description | Applications |
        |--------------|-------------|--------------|
        | RÃ©seaux de neurones convolutifs (CNN) | Utilisent des couches convolutionnelles pour extraire des caractÃ©ristiques spatiales | Vision par ordinateur, reconnaissance d'images |
        | RÃ©seaux de neurones rÃ©currents (RNN) | ConÃ§us pour traiter des sÃ©quences de donnÃ©es en utilisant des connexions rÃ©currentes | Traitement du langage naturel, sÃ©ries temporelles |
        | Transformeurs | Utilisent des mÃ©canismes d'attention pour capturer les dÃ©pendances Ã  long terme dans les donnÃ©es sÃ©quentielles | Traduction automatique, modÃ¨les de langage |
        | Autoencodeurs | RÃ©seaux non supervisÃ©s utilisÃ©s pour la rÃ©duction de dimensionnalitÃ© et la gÃ©nÃ©ration de donnÃ©es | Compression de donnÃ©es, gÃ©nÃ©ration d'images |
        :::

        :::warning DÃ©fis de l'apprentissage profond
        MalgrÃ© ses succÃ¨s, l'apprentissage profond prÃ©sente plusieurs dÃ©fis :
        - **DonnÃ©es massives** : NÃ©cessite de grandes quantitÃ©s de donnÃ©es Ã©tiquetÃ©es pour un entraÃ®nement efficace.
        - **CoÃ»t computationnel** : EntraÃ®nement de modÃ¨les profonds demande des ressources matÃ©rielles importantes (GPU/TPU).
        - **InterprÃ©tabilitÃ©** : Les modÃ¨les profonds sont souvent considÃ©rÃ©s comme des "boÃ®tes noires", rendant difficile la comprÃ©hension de leurs dÃ©cisions.
        - **Surapprentissage** : Risque accru de surapprentissage en raison de la complexitÃ© des modÃ¨les.
        - **Biais** : Les modÃ¨les peuvent apprendre et amplifier les biais prÃ©sents dans les donnÃ©es d'entraÃ®nement.
        :::

        :::info Exemple d'implÃ©mentation avec Keras (rÃ©seaux de neurones)

        Voici un exemple d'utilisation de la bibliothÃ¨que `Keras` (incluse dans `TensorFlow`) pour entraÃ®ner un **rÃ©seau de neurones simple** sur le jeu de donnÃ©es `MNIST` (images de chiffres manuscrits 28Ã—28).

        Ce jeu de donnÃ©es est constituÃ© d'environ 60 000 images de chiffres (0 Ã  9) Ã©crits Ã  la main.<br />
        Le but est de construire un modÃ¨le capable de reconnaÃ®tre correctement des chiffres Ã©crits Ã  la main.

        L'objectif est de montrer les grandes Ã©tapes d'un entraÃ®nement en deep learning :

        1. Charger un jeu de donnÃ©es intÃ©grÃ© Ã  Keras
        2. PrÃ©traiter les donnÃ©es (normalisation, mise en forme)
        3. CrÃ©er un modÃ¨le (architecture)
        4. Compiler le modÃ¨le (choix de la fonction de perte, de lâ€™optimiseur, des mÃ©triques)
        5. EntraÃ®ner le modÃ¨le (`fit`)
        6. Ã‰valuer sur un ensemble de test

        > ğŸ’¡ Cet exemple est surtout **illustratif** : pour lâ€™exÃ©cuter, il faut avoir installÃ© `tensorflow` (qui contient `keras`).

        ```python
        # 1. Importer les bibliothÃ¨ques nÃ©cessaires
        import tensorflow as tf
        from tensorflow import keras
        from tensorflow.keras import layers

        # 2. Charger le jeu de donnÃ©es MNIST
        #    (images de chiffres manuscrits 28x28 en niveaux de gris)
        (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

        print("Taille x_train :", x_train.shape)
        print("Taille y_train :", y_train.shape)
        print("Taille x_test  :", x_test.shape)
        print("Taille y_test  :", y_test.shape)

        # 3. PrÃ©traitement des donnÃ©es
        #    - Conversion en float32
        #    - Normalisation des pixels dans [0, 1]
        x_train = x_train.astype("float32") / 255.0
        x_test  = x_test.astype("float32") / 255.0

        #    On rÃ©serve une partie de x_train pour la validation
        x_val = x_train[-10000:]
        y_val = y_train[-10000:]

        x_train = x_train[:-10000]
        y_train = y_train[:-10000]

        print("AprÃ¨s split :")
        print("EntraÃ®nement :", x_train.shape, y_train.shape)
        print("Validation   :", x_val.shape,   y_val.shape)
        print("Test         :", x_test.shape,  y_test.shape)

        #    Les images 28x28 sont aplaties en vecteurs de taille 784
        x_train = x_train.reshape((-1, 28 * 28))
        x_val   = x_val.reshape((-1, 28 * 28))
        x_test  = x_test.reshape((-1, 28 * 28))

        # 4. DÃ©finir le modÃ¨le (rÃ©seau de neurones fully-connected)
        model = keras.Sequential(
            [
                layers.Input(shape=(784,)),              # 28*28 pixels
                layers.Dense(128, activation="relu"),    # Couche cachÃ©e 1
                layers.Dense(64, activation="relu"),     # Couche cachÃ©e 2
                layers.Dense(10, activation="softmax"),  # 10 classes (chiffres 0â€“9)
            ]
        )

        # Afficher un rÃ©sumÃ© du modÃ¨le
        model.summary()

        # 5. Compiler le modÃ¨le
        #    - Optimiseur : Adam
        #    - Perte : entropie croisÃ©e pour labels entiers (sparse_categorical_crossentropy)
        #    - MÃ©trique : accuracy
        model.compile(
            optimizer="adam",
            loss="sparse_categorical_crossentropy",
            metrics=["accuracy"],
        )

        # 6. EntraÃ®ner le modÃ¨le
        history = model.fit(
            x_train,
            y_train,
            epochs=5,                # Nombre de passes sur les donnÃ©es d'entraÃ®nement
            batch_size=32,           # Taille des mini-lots
            validation_data=(x_val, y_val),
        )

        # 7. Ã‰valuer la performance sur l'ensemble de test
        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
        print(f"Loss sur le test : {test_loss:.4f}")
        print(f"Accuracy sur le test : {test_acc:.4f}")

        # 8. Faire quelques prÃ©dictions (optionnel)
        import numpy as np

        samples = x_test[:5]
        labels  = y_test[:5]

        pred_probas = model.predict(samples)
        pred_labels = np.argmax(pred_probas, axis=1)

        print("Labels rÃ©els     :", labels)
        print("Labels prÃ©dits   :", pred_labels)
        :::

    </TabItem>

    <TabItem value="ecologisation" label="ğŸŒ³ Empreinte Ã©cologique">

        :::tip ğŸŒ Pourquoi parler dâ€™empreinte Ã©cologique de lâ€™IA?

        DerriÃ¨re chaque requÃªte Ã  un modÃ¨le dâ€™IA, il y a :

        - des **centres de donnÃ©es** ğŸ¢ remplis de serveurs et de GPU ;
        - une **consommation dâ€™Ã©lectricitÃ©** âš¡ (souvent produite Ã  partir de combustibles fossiles) ;
        - du **refroidissement** ğŸ’§ (eau, climatisation) ;
        - et du **matÃ©riel** Ã  fabriquer puis Ã  recycler (mÃ©taux, terres rares, dÃ©chets Ã©lectroniques).

        Selon lâ€™Agence internationale de lâ€™Ã©nergie (AIE), les centres de donnÃ©es consommaient dÃ©jÃ  autour de **1,5 %** de lâ€™Ã©lectricitÃ© mondiale en 2024, et cette part pourrait **doubler** dâ€™ici 2030, en grande partie Ã  cause de lâ€™IA.  [oai_citation:0â€¡IEA](https://www.iea.org/reports/energy-and-ai/executive-summary?utm_source=chatgpt.com)

        :::

        :::warning ğŸ§© OÃ¹ se situe lâ€™impact?

        On peut simplifier lâ€™empreinte Ã©cologique de lâ€™IA en trois grandes composantes :

        1. **EntraÃ®nement des modÃ¨les**
           - EntraÃ®ner un grand modÃ¨le (par ex. un grand modÃ¨le de langage) peut consommer des **dizaines de GWh** dâ€™Ã©lectricitÃ©.
           - Certaines estimations pour des modÃ¨les de type GPT-3 parlent de **centaines de tonnes de COâ‚‚e** Ã©mises pour un seul entraÃ®nement.  [oai_citation:1â€¡The Sustainable Agency](https://thesustainableagency.com/blog/environmental-impact-of-generative-ai/?utm_source=chatgpt.com)
           - Cela reprÃ©sente lâ€™Ã©quivalent de **centaines de vols long-courrier** ou de la **vie entiÃ¨re** dâ€™Ã©missions dâ€™une voiture moyenne.

        2. **Utilisation quotidienne (infÃ©rence)**
           - Une fois le modÃ¨le dÃ©ployÃ©, chaque requÃªte (chat, image, recommandationâ€¦) consomme de lâ€™Ã©nergie.
           - Google estimait dÃ©jÃ  quâ€™environ **60 %** de lâ€™Ã©nergie liÃ©e Ã  lâ€™IA Ã©tait consommÃ©e par lâ€™**infÃ©rence** (usage quotidien), contre 40 % pour lâ€™entraÃ®nement.  [oai_citation:2â€¡news.climate.columbia.edu](https://news.climate.columbia.edu/2023/06/09/ais-growing-carbon-footprint/?utm_source=chatgpt.com)
           - Avec des millions dâ€™utilisateurs, ces â€œpetitesâ€ requÃªtes sâ€™additionnent.

        3. **Eau et refroidissement**
           - Les centres de donnÃ©es utilisent de grandes quantitÃ©s dâ€™**eau** pour le refroidissement.
           - Une Ã©tude estimait par exemple quâ€™un entraÃ®nement de GPT-3 avait nÃ©cessitÃ© de lâ€™ordre de **700 000 L dâ€™eau douce** pour le refroidissement, lâ€™Ã©quivalent de la fabrication de centaines de voitures.  [oai_citation:3â€¡Earth.Org](https://earth.org/environmental-impact-chatgpt/?utm_source=chatgpt.com)

        Pour visualiser le chemin de lâ€™impact :

        ```mermaid
        flowchart LR
            U["ğŸ‘©â€ğŸ’» Vous<br/><sub>(code, requÃªtes)</sub>"] --> R["RequÃªtes vers un modÃ¨le d'IA"]
            R --> DC["ğŸ¢ Centre de donnÃ©es<br/><sub>GPU, serveurs</sub>"]

            DC --> P["âš¡ Ã‰lectricitÃ©<br/><sub>mix Ã©nergÃ©tique local</sub>"]
            P --> CO2["ğŸŒ«ï¸ Ã‰missions de COâ‚‚e"]

            DC --> Cool["ğŸ’§ Refroidissement<br/><sub>eau, climatisation</sub>"]

            DC --> HW["ğŸ› ï¸ MatÃ©riel informatique"]
            HW --> Waste["ğŸ—‘ï¸ DÃ©chets Ã©lectroniques<br/><sub>extraction, recyclage</sub>"]
        ```

        :::

        :::info ğŸ“Š Ordres de grandeur (approximatifs)

        Ces chiffres Ã©voluent vite, mais donnent une idÃ©e des Ã©chelles :

        | Aspect | Ordre de grandeur | Source / contexte |
        |--------|-------------------|--------------------|
        | Part de lâ€™Ã©lectricitÃ© mondiale utilisÃ©e par les centres de donnÃ©es | ~1,5 % en 2024 | AIE (Energy and AI)  [oai_citation:4â€¡IEA](https://www.iea.org/reports/energy-and-ai/executive-summary?utm_source=chatgpt.com) |
        | Projection pour 2030 | Jusquâ€™Ã  ~3 % de lâ€™Ã©lectricitÃ© mondiale | AIE, scÃ©narios 2030  [oai_citation:5â€¡IEA](https://www.iea.org/reports/energy-and-ai/energy-demand-from-ai?utm_source=chatgpt.com) |
        | EntraÃ®nement dâ€™un trÃ¨s grand modÃ¨le | centaines de milliers de kg de COâ‚‚e (â‰ˆ centaines de vols long-courrier) | Ã©tudes sur GPT-3 et autres grands modÃ¨les  [oai_citation:6â€¡The Sustainable Agency](https://thesustainableagency.com/blog/environmental-impact-of-generative-ai/?utm_source=chatgpt.com) |
        | Eau utilisÃ©e pour lâ€™entraÃ®nement dâ€™un grand modÃ¨le | ~700 000 L pour un entraÃ®nement (ordre de grandeur) | Ã©tude sur GPT-3  [oai_citation:7â€¡Earth.Org](https://earth.org/environmental-impact-chatgpt/?utm_source=chatgpt.com) |

        > ğŸ§Š Ã€ lâ€™Ã©chelle dâ€™un **TP en cÃ©gep**, votre impact est trÃ¨s faible comparÃ© Ã  celui de grands modÃ¨les industriels.
        > Mais comprendre ces ordres de grandeur permet de rÃ©flÃ©chir Ã  une **pratique plus sobre** dÃ¨s maintenant.

        :::

        :::tip ğŸŒ± Vers une IA plus â€œverteâ€ (Green AI)

        Des Ã©quipes de recherche et dâ€™ingÃ©nierie travaillent Ã  rÃ©duire lâ€™empreinte Ã©cologique de lâ€™IA, ce quâ€™on appelle parfois **Green AI**.  [oai_citation:8â€¡ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0925231224008671?utm_source=chatgpt.com)
        Parmi les stratÃ©gies :

        - **ModÃ¨les plus petits et efficaces**
          - Utiliser des modÃ¨les plus compacts quand câ€™est possible (au lieu de toujours choisir â€œle plus gros modÃ¨leâ€).
          - Techniques de **compression**, **quantification**, **distillation** pour rÃ©duire la taille des modÃ¨les.  [oai_citation:9â€¡esdst.eu](https://esdst.eu/green-ai-reducing-the-carbon-footprint-of-machine-learning/?utm_source=chatgpt.com)

        - **MatÃ©riel et infrastructures plus sobres**
          - Data centers alimentÃ©s par des **Ã©nergies renouvelables** (solaire, Ã©olien, hydro).
          - Serveurs et GPU plus efficaces sur le plan Ã©nergÃ©tique.

        - **Optimisation des entraÃ®nements**
          - Limiter le nombre dâ€™expÃ©riences redondantes.
          - Planifier les entraÃ®nements aux moments oÃ¹ lâ€™Ã©lectricitÃ© est plus â€œpropreâ€ (forte part de renouvelable).  [oai_citation:10â€¡research.google](https://research.google/blog/good-news-about-the-carbon-footprint-of-machine-learning-training/?utm_source=chatgpt.com)

        - **Mesure du carbone**
          - Utiliser des outils comme **CodeCarbon** ou autres frameworks pour estimer lâ€™empreinte carbone dâ€™un entraÃ®nement.
          - IntÃ©grer cette information dans les choix de modÃ¨les et dâ€™architectures.  [oai_citation:11â€¡InfoQ](https://www.infoq.com/articles/best-practices-energy-efficient-ai-ml-systems/?utm_source=chatgpt.com)

        :::

        :::tip ğŸ§® Et vous, en SN1, concrÃ¨tement?

        Ã€ votre Ã©chelle (TP en Python, petits modÃ¨les, jeux de donnÃ©es modestes), lâ€™impact direct est trÃ¨s faible, mais vous pouvez dÃ©jÃ  adopter de **bons rÃ©flexes** :

        - **Ã‰viter le gaspillage de calcul**
          - Ne pas lancer 50 fois le mÃªme entraÃ®nement â€œpour rienâ€.
          - Sauvegarder les modÃ¨les entraÃ®nÃ©s au lieu de tout refaire Ã  chaque exÃ©cution.

        - **Commencer simple**
          - Tester dâ€™abord des **modÃ¨les simples** (rÃ©gression, petits arbres, petits rÃ©seaux).
          - Nâ€™augmenter la complexitÃ© **que si nÃ©cessaire**.

        - **RÃ©utiliser plutÃ´t que tout recrÃ©er**
          - Quand câ€™est possible, utiliser des **modÃ¨les prÃ©-entraÃ®nÃ©s** lÃ©gers ou des bibliothÃ¨ques optimisÃ©es (scikit-learn, etc.).

        - **ÃŠtre curieuxÂ·se de la question**
          - Lorsquâ€™on vous prÃ©sente un nouvel outil dâ€™IA, vous pouvez poser la question :
            > â€œEt son **empreinte Ã©cologique**, on sait quelque chose lÃ -dessus?â€
          - Câ€™est dÃ©jÃ  une maniÃ¨re de faire Ã©voluer les pratiques.

        Lâ€™objectif nâ€™est pas de vous culpabiliser dÃ¨s maintenant, mais de vous donner des **repÃ¨res** :
        lâ€™IA nâ€™est pas â€œmagiqueâ€ ni â€œimmatÃ©rielleâ€, elle repose sur des infrastructures bien rÃ©elles, avec un **coÃ»t Ã©nergÃ©tique et matÃ©riel**. ğŸŒ±

        :::

    </TabItem>

    <TabItem value="TP2" label="ğŸ›  TP2">
        :::tip ğŸ› 
        Profitez de cette sÃ©ance pour dÃ©buter votre [travail pratique 2](/tp/tp2).
        :::
    </TabItem>

</Tabs>
